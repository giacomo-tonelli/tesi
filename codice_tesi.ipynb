{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2QKokmA6xckM7A0ZXMDcx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8eb71bdf19fb41efa5087836cc3ac153": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba0c3172c2dd4fea8df480f0c9dfd372",
              "IPY_MODEL_8da878eaf70b422cbe5424af1c1fa506",
              "IPY_MODEL_ac0e3a2d044b4f1cb5d08785267d1382"
            ],
            "layout": "IPY_MODEL_8d462602ae364df2bd084e5ec4482bce"
          }
        },
        "ba0c3172c2dd4fea8df480f0c9dfd372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03112045686f4a78997188cba1444053",
            "placeholder": "​",
            "style": "IPY_MODEL_2e824cba482a4b8b9425c58a6c8000e5",
            "value": "Processing rows:  30%"
          }
        },
        "8da878eaf70b422cbe5424af1c1fa506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_951c22e14bf74fb09860e087d24b523b",
            "max": 400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78fc249087fb4fe49b8a45b5ed725f3b",
            "value": 121
          }
        },
        "ac0e3a2d044b4f1cb5d08785267d1382": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c00b1eb75aa463ab11b53e080d14a4c",
            "placeholder": "​",
            "style": "IPY_MODEL_4029b1cdcfa2454a994e1c1085c5dddf",
            "value": " 121/400 [19:01&lt;38:03,  8.18s/it]"
          }
        },
        "8d462602ae364df2bd084e5ec4482bce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03112045686f4a78997188cba1444053": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e824cba482a4b8b9425c58a6c8000e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "951c22e14bf74fb09860e087d24b523b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78fc249087fb4fe49b8a45b5ed725f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c00b1eb75aa463ab11b53e080d14a4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4029b1cdcfa2454a994e1c1085c5dddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giacomo-tonelli/tesi/blob/main/codice_tesi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CAMBIARE RUN TIME"
      ],
      "metadata": {
        "id": "an-fIZ1mDD2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnxNA2PIrrr4",
        "outputId": "cb14b714-5707-44e9-d880-2c3a5b8efd66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bitsandbytes-0.46.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "riavviare runtime dopo l installazione di bitsandbytes"
      ],
      "metadata": {
        "id": "5ySL-uLv7tSs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHst3kz1qH7Q",
        "outputId": "44147947-17ed-4992-d4ba-da92a0024c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive montato con successo!\n",
            "Tentativo di caricare il modello da: /content/drive/MyDrive/Mistral-7B-Instruct-v0.2 con quantizzazione a 4-bit su GPU.\n",
            "Tokenizer caricato e pad_token impostato.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/quantizers/auto.py:222: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
            "  warnings.warn(warning_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modello caricato. Dispositivo principale del modello: cuda:0\n",
            "Parametri del modello allocati su: cuda:0\n",
            "\n",
            "--- Setup GPU completato. 'model' e 'tokenizer' sono pronti. ---\n"
          ]
        }
      ],
      "source": [
        "# --- Blocco 1: Setup Iniziale per Mistral-7B-Instruct-v0.2 su GPU ---\n",
        "\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import threading\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoConfig\n",
        "import torch\n",
        "\n",
        "# 1. Montare Google Drive\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=True) # force_remount può essere utile\n",
        "    print(\"Google Drive montato con successo!\")\n",
        "except Exception as e:\n",
        "    print(f\"Errore durante il montaggio di Google Drive: {e}\")\n",
        "    raise SystemExit(\"Impossibile montare Google Drive. Verifica i permessi.\")\n",
        "\n",
        "# 2. Definire il percorso del modello salvato su Drive e configura la quantizzazione\n",
        "\n",
        "model_path_on_drive = \"/content/drive/MyDrive/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "# Controllo disponibilità CUDA (GPU)\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"ERRORE: GPU non disponibile. Assicurati di aver selezionato un runtime con GPU (Runtime -> Change runtime type).\")\n",
        "    raise SystemExit(\"GPU non trovata.\")\n",
        "\n",
        "# Configurazione per la quantizzazione a 4-bit\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16 # Cambiato a float16 come suggerito per compatibilità GPU\n",
        ")\n",
        "print(f\"Tentativo di caricare il modello da: {model_path_on_drive} con quantizzazione a 4-bit su GPU.\")\n",
        "\n",
        "# 3. Carica Tokenizer e Modello su GPU\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path_on_drive)\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "    print(\"Tokenizer caricato e pad_token impostato.\")\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_path_on_drive,\n",
        "        quantization_config=bnb_config, # quantizzazione\n",
        "        device_map=\"auto\",  # accelerate gestisce il mapping sulla GPU\n",
        "        torch_dtype=torch.float16 # Dovrebbe corrispondere a bnb_4bit_compute_dtype\n",
        "                                   # anche qui provare torch.float16 se bfloat16 da problemi\n",
        "    )\n",
        "    model.eval() # Imposta il modello in modalità valutazione\n",
        "\n",
        "    # Verifica dispositivo\n",
        "    if hasattr(model, 'device'):\n",
        "        print(f\"Modello caricato. Dispositivo principale del modello: {model.device}\")\n",
        "        if len(list(model.parameters())) > 0:\n",
        "            param_device = next(model.parameters()).device\n",
        "            print(f\"Parametri del modello allocati su: {param_device}\")\n",
        "            if \"cuda\" not in str(param_device):\n",
        "                print(\"ATTENZIONE: Il modello potrebbe non essere sulla GPU come previsto!\")\n",
        "        else:\n",
        "             print(\"ATTENZIONE: Modello senza parametri?\")\n",
        "    else:\n",
        "        print(\"Modello caricato, ma l'attributo 'device' non è direttamente accessibile.\")\n",
        "\n",
        "\n",
        "except ImportError as e_imp:\n",
        "    print(f\"ImportError: {e_imp}\")\n",
        "    print(\"Questo errore spesso indica che 'bitsandbytes' non è installato correttamente o il kernel non è stato riavviato dopo l'installazione.\")\n",
        "    print(\"Prova ad aggiungere '!pip install -U bitsandbytes' all'inizio di questa cella, eseguila, POI RIAVVIA IL RUNTIME (Menu Runtime > Riavvia sessione) e riesegui questa cella.\")\n",
        "    raise SystemExit(\"Errore di importazione, probabilmente bitsandbytes.\")\n",
        "except Exception as e:\n",
        "    print(f\"Errore durante il caricamento del modello {model_path_on_drive} da Drive: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    raise SystemExit(\"Impossibile caricare il modello da Drive.\")\n",
        "\n",
        "print(\"\\n--- Setup GPU completato. 'model' e 'tokenizer' sono pronti. ---\")\n",
        "\n",
        "# --- Variabile globale per il prompt dell'utente ---\n",
        "user_prompt_template = \"\"\"\n",
        "You are an expert analyst specializing in patents and scientific literature.\n",
        "Your task is to read technical texts and distill their core technological concepts into clear, concise sentences.\n",
        "You excel at identifying the main purpose of an invention or research (Function), explaining how it works (Solution), and stating where it can be applied (Application).\n",
        "Your summaries are precise, scientifically accurate, and easily understandable to researchers and professionals.\n",
        "\n",
        "Text:\n",
        "{text}\n",
        "\n",
        "Respond ONLY in the following JSON format and the response MUST start with {{ and end with }}:\n",
        "\n",
        "{{\n",
        "  \"function\": \"<brief summary of the main purpose, in verb-object form>\",\n",
        "  \"solution\": \"<brief technical explanation of how the purpose is achieved>\",\n",
        "  \"application\": \"<brief summary of practical or industrial domains where it applies>\"\n",
        "}}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Blocco 2: Definizione delle Funzioni di Elaborazione ---\n",
        "\n",
        "# Verifica che le variabili dal setup siano presenti\n",
        "if 'model' not in globals() or 'tokenizer' not in globals() or 'user_prompt_template' not in globals():\n",
        "    print(\"ERRORE CRITICO: 'model', 'tokenizer', o 'user_prompt_template' non sono definiti.\")\n",
        "    print(\"Esegui prima la CELLA 1 (Setup Iniziale).\")\n",
        "    raise SystemExit(\"Setup del modello non completato.\")\n",
        "\n",
        "REQUIRED_KEYS_EXTRACT = {\"function\", \"solution\", \"application\"}\n",
        "def is_valid_output_extract(output): # Usata dopo in extract_concepts\n",
        "    if not isinstance(output, dict):\n",
        "        return False\n",
        "    return REQUIRED_KEYS_EXTRACT.issubset(output.keys())\n",
        "\n",
        "save_lock = threading.Lock() # Per la scrittura su file thread-safe\n",
        "\n",
        "def save_block_to_jsonl(results, path='results_patent.jsonl'):\n",
        "    with save_lock:\n",
        "        with open(path, 'a', encoding='utf-8') as f:\n",
        "            for r in results:\n",
        "                f.write(json.dumps(r, ensure_ascii=False) + '\\n')\n",
        "\n",
        "def get_already_processed_patent_ids(jsonl_path):\n",
        "    if not os.path.exists(jsonl_path):\n",
        "        return set()\n",
        "    done = set()\n",
        "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                obj = json.loads(line)\n",
        "                if \"patent_id\" in obj:\n",
        "                    done.add(str(obj[\"patent_id\"]))\n",
        "            except Exception:\n",
        "                continue\n",
        "    return done\n",
        "\n",
        "def is_valid_final_output(result): # Usata dopo in process_batch prima di salvare\n",
        "    if not isinstance(result, dict): return False\n",
        "    return all(k in result and isinstance(result[k], str) for k in [\"function\", \"solution\", \"application\", \"patent_id\"])\n",
        "\n",
        "# MODIFICA aggiunta per DEBUG: extract_concepts\n",
        "def extract_concepts(text):\n",
        "    global model, tokenizer, user_prompt_template # per assicurare l'uso delle variabili globali\n",
        "    chat_messages = [{\"role\": \"user\", \"content\": user_prompt_template.format(text=text)}]\n",
        "    try:\n",
        "        prompt_for_llm = tokenizer.apply_chat_template(chat_messages, tokenize=False, add_generation_prompt=True)\n",
        "    except Exception as e:\n",
        "        print(f\"DEBUG extract_concepts: Errore apply_chat_template: {e}\")\n",
        "        return None\n",
        "\n",
        "    inputs = tokenizer(prompt_for_llm, return_tensors=\"pt\", return_attention_mask=True).to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=512,\n",
        "            do_sample=False,\n",
        "            pad_token_id=tokenizer.pad_token_id\n",
        "        )\n",
        "\n",
        "    generated_ids = outputs[0][inputs['input_ids'].shape[-1]:]\n",
        "    decoded_output = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
        "    #print(f\"\\nDEBUG decoded_output COMPLETO:\\n{decoded_output}\\n\")\n",
        "\n",
        "    json_match = re.search(r'\\{[\\s\\S]*\\}', decoded_output)\n",
        "    #json_match = re.search(r'\\{[\\s\\S]*?\\}', decoded_output)\n",
        "    cleaned_json_str = None\n",
        "    if json_match:\n",
        "        json_str_raw = json_match.group().strip()\n",
        "        if json_str_raw.startswith(\"```json\"):\n",
        "            json_str_raw = json_str_raw[len(\"```json\"):].strip()\n",
        "        if json_str_raw.endswith(\"```\"):\n",
        "            json_str_raw = json_str_raw[:-len(\"```\")].strip()\n",
        "        cleaned_json_str = json_str_raw\n",
        "\n",
        "    if cleaned_json_str:\n",
        "        try:\n",
        "            parsed_json = json.loads(cleaned_json_str)\n",
        "            if is_valid_output_extract(parsed_json):\n",
        "                print(\"DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\")\n",
        "                return parsed_json\n",
        "            else:\n",
        "                print(\"DEBUG extract_concepts: JSON PARSATO MA NON VALIDO (mancano chiavi 'function', 'solution', o 'application').\")\n",
        "                print(f\"DEBUG extract_concepts: Chiavi trovate: {list(parsed_json.keys())}\")\n",
        "                return None\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"DEBUG extract_concepts: JSONDecodeError: '{e}'\")\n",
        "            print(f\"DEBUG extract_concepts: Stringa JSON (pulita) che ha causato l'errore (primi 200): '{cleaned_json_str[:200]}...'\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"DEBUG extract_concepts: Nessun blocco JSON trovato nell'output dell'LLM con regex.\")\n",
        "        return None\n",
        "\n",
        "def process_row(index, row):\n",
        "    global model, tokenizer # Anche se non usate direttamente qui, extract_concepts le usa\n",
        "    try:\n",
        "        text_parts = []\n",
        "        if \"appln_title\" in row and pd.notna(row[\"appln_title\"]): text_parts.append(str(row[\"appln_title\"]))\n",
        "        if \"appln_abstract\" in row and pd.notna(row[\"appln_abstract\"]): text_parts.append(str(row[\"appln_abstract\"]))\n",
        "        if not text_parts:\n",
        "            print(f\"DEBUG process_row: Riga {index} non ha titolo/abstract. Salto.\")\n",
        "            return None\n",
        "        text = \". \".join(text_parts)\n",
        "\n",
        "        result_from_llm = extract_concepts(text)\n",
        "        if result_from_llm is None: return None\n",
        "\n",
        "        if \"patent\" in row and pd.notna(row[\"patent\"]):\n",
        "            result_from_llm[\"patent_id\"] = str(row[\"patent\"])\n",
        "        else:\n",
        "            print(f\"DEBUG process_row: Riga {index} manca 'patent_id' (colonna 'patent' nel df). Scartata.\")\n",
        "            return None\n",
        "        return result_from_llm\n",
        "    except Exception as e:\n",
        "        print(f\"DEBUG process_row: Errore imprevisto riga {index}: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_batch(current_batch_df, path_to_save_results):\n",
        "    batch_results_list = []\n",
        "    print(f\"    DEBUG process_batch: Inizio elaborazione di {len(current_batch_df)} righe...\")\n",
        "    for original_index, row_data in current_batch_df.iterrows():\n",
        "        single_row_result = process_row(original_index, row_data)\n",
        "        if single_row_result is not None:\n",
        "            batch_results_list.append(single_row_result)\n",
        "\n",
        "    print(f\"    DEBUG process_batch: Elaborazione batch completata. Ottenuti {len(batch_results_list)} risultati grezzi.\")\n",
        "    valid_results_for_saving = [r for r in batch_results_list if is_valid_final_output(r)]\n",
        "\n",
        "    if len(valid_results_for_saving) > 0:\n",
        "        if len(valid_results_for_saving) < len(batch_results_list):\n",
        "            print(f\"    DEBUG process_batch: ATTENZIONE - {len(batch_results_list) - len(valid_results_for_saving)} risultati grezzi non validi e scartati.\")\n",
        "        save_block_to_jsonl(valid_results_for_saving, path_to_save_results)\n",
        "        print(f\"    DEBUG process_batch: Batch salvato con {len(valid_results_for_saving)} risultati validi su {path_to_save_results}.\")\n",
        "    else:\n",
        "        print(f\"    DEBUG process_batch: Nessun risultato valido da salvare per questo batch.\")\n",
        "    return len(valid_results_for_saving)\n",
        "\n",
        "print(\"--- Funzioni di elaborazione definite. ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yreSpYowqRKh",
        "outputId": "189d0fc8-3627-4ebc-afca-aea009a8bc04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Funzioni di elaborazione definite. ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prova con output che non stampa i debug ma la percentuale di completamento e che salva riga per riga senza aspettare la fine del batch\n",
        "# --- Blocco 3: Esecuzione Principale con Salvataggio Riga per Riga e Barra di Progresso ---\n",
        "from tqdm.auto import tqdm # Importa tqdm per la barra di progresso\n",
        "\n",
        "# Verifica che le variabili e funzioni cruciali siano definite\n",
        "if 'df' not in globals() and ('model' not in globals() or 'tokenizer' not in globals() or 'process_row' not in globals()):\n",
        "    print(\"ERRORE CRITICO: DataFrame 'df' O ('model', 'tokenizer', 'process_row') non definiti.\")\n",
        "    print(\"Esegui prima la CELLA 1 (Setup) e la CELLA 2 (Definizione Funzioni). Poi carica 'df'.\")\n",
        "    # Tenta di caricare df se non definito\n",
        "    try:\n",
        "        df_path = r\"/content/drive/MyDrive/data_giacomo.csv\"\n",
        "        print(f\"Tentativo di caricare il DataFrame da: {df_path}\")\n",
        "        df = pd.read_csv(df_path)\n",
        "        print(f\"DataFrame caricato con {len(df)} righe.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ERRORE: File DataFrame '{df_path}' non trovato. Impossibile procedere.\")\n",
        "        raise SystemExit(\"DataFrame non trovato.\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERRORE durante il caricamento del DataFrame: {e}\")\n",
        "        raise SystemExit(\"Errore caricamento DataFrame.\")\n",
        "elif 'df' not in globals(): # Se model, tokenizer, ecc. sono definiti ma df no\n",
        "    try:\n",
        "        df_path = r\"/content/drive/MyDrive/data_giacomo.csv\"\n",
        "        print(f\"Tentativo di caricare il DataFrame da: {df_path}\")\n",
        "        df = pd.read_csv(df_path)\n",
        "        print(f\"DataFrame caricato con {len(df)} righe.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ERRORE: File DataFrame '{df_path}' non trovato. Impossibile procedere.\")\n",
        "        raise SystemExit(\"DataFrame non trovato.\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERRORE durante il caricamento del DataFrame: {e}\")\n",
        "        raise SystemExit(\"Errore caricamento DataFrame.\")\n",
        "else:\n",
        "     print(f\"DataFrame 'df' ({len(df)} righe), Setup modello e funzioni OK. Procedo.\")\n",
        "\n",
        "\n",
        "results_path = \"/content/drive/MyDrive/results_patent_mistral7b_gpu.jsonl\"\n",
        "print(f\"\\nL'output verrà salvato riga per riga in: {results_path}\")\n",
        "print(\"Assicurati che le colonne 'patent', 'appln_title', 'appln_abstract' siano presenti nel DataFrame 'df'.\")\n",
        "\n",
        "NUMERO_RIGHE_DA_PROCESSARE_ORA = 400\n",
        "\n",
        "done_patent_ids = get_already_processed_patent_ids(results_path)\n",
        "print(f\"Trovati {len(done_patent_ids)} patent_id già processati nel file di output.\")\n",
        "\n",
        "if \"patent\" not in df.columns:\n",
        "    print(\"ERRORE: La colonna 'patent' non esiste nel DataFrame 'df'.\")\n",
        "else:\n",
        "    df_all_new_rows = df[~df[\"patent\"].astype(str).isin(done_patent_ids)]\n",
        "    print(f\"Numero di righe totali nel DataFrame 'df': {len(df)}\")\n",
        "    print(f\"Numero di righe nuove (non ancora processate): {len(df_all_new_rows)}\")\n",
        "\n",
        "    if len(df_all_new_rows) == 0:\n",
        "        print(\"Nessuna nuova riga da processare.\")\n",
        "    else:\n",
        "        df_this_run = df_all_new_rows.head(NUMERO_RIGHE_DA_PROCESSARE_ORA)\n",
        "\n",
        "        if len(df_this_run) == 0:\n",
        "            print(f\"Nessuna riga selezionata per questa esecuzione (limite: {NUMERO_RIGHE_DA_PROCESSARE_ORA} o nessuna riga nuova).\")\n",
        "        else:\n",
        "            print(f\"Verranno processate e salvate individualmente le prossime {len(df_this_run)} righe.\")\n",
        "\n",
        "            processed_count_in_this_run = 0\n",
        "            # Itera sulle righe selezionate per barra di progresso\n",
        "            for original_index, row_data in tqdm(df_this_run.iterrows(), total=len(df_this_run), desc=\"Processing rows\"):\n",
        "                try:\n",
        "                    # Processa la singola riga\n",
        "                    single_row_result = process_row(original_index, row_data)\n",
        "\n",
        "                    if single_row_result is not None:\n",
        "                        # Valida il risultato finale (include patent_id)\n",
        "                        if is_valid_final_output(single_row_result):\n",
        "                            # Salva il singolo risultato valido\n",
        "                            save_block_to_jsonl([single_row_result], results_path)\n",
        "                            processed_count_in_this_run += 1\n",
        "                except Exception as e_row_proc:\n",
        "                    print(f\"ERRORE grave durante l'elaborazione della riga con indice originale {original_index}: {e_row_proc}\")\n",
        "                    # import traceback; traceback.print_exc() # Per debug più approfondito\n",
        "\n",
        "            print(f\"\\n--- Elaborazione di {len(df_this_run)} righe richiesta completata. ---\")\n",
        "            print(f\"Salvati {processed_count_in_this_run} risultati validi in questo run.\")\n",
        "\n",
        "    print(f\"Controlla il file di output: {results_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8eb71bdf19fb41efa5087836cc3ac153",
            "ba0c3172c2dd4fea8df480f0c9dfd372",
            "8da878eaf70b422cbe5424af1c1fa506",
            "ac0e3a2d044b4f1cb5d08785267d1382",
            "8d462602ae364df2bd084e5ec4482bce",
            "03112045686f4a78997188cba1444053",
            "2e824cba482a4b8b9425c58a6c8000e5",
            "951c22e14bf74fb09860e087d24b523b",
            "78fc249087fb4fe49b8a45b5ed725f3b",
            "8c00b1eb75aa463ab11b53e080d14a4c",
            "4029b1cdcfa2454a994e1c1085c5dddf"
          ]
        },
        "id": "ho6L8rSGzZSH",
        "outputId": "7c0a1827-cc6c-461c-896d-6252f7c41876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame 'df' (152456 righe), Setup modello e funzioni OK. Procedo.\n",
            "\n",
            "L'output verrà salvato riga per riga in: /content/drive/MyDrive/results_patent_mistral7b_gpu.jsonl\n",
            "Assicurati che le colonne 'patent', 'appln_title', 'appln_abstract' siano presenti nel DataFrame 'df'.\n",
            "Trovati 8800 patent_id già processati nel file di output.\n",
            "Numero di righe totali nel DataFrame 'df': 152456\n",
            "Numero di righe nuove (non ancora processate): 117168\n",
            "Verranno processate e salvate individualmente le prossime 400 righe.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing rows:   0%|          | 0/400 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8eb71bdf19fb41efa5087836cc3ac153"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG extract_concepts: JSONDecodeError: 'Expecting ',' delimiter: line 3 column 89 (char 241)'\n",
            "DEBUG extract_concepts: Stringa JSON (pulita) che ha causato l'errore (primi 200): '{\n",
            "  \"function\": \"Synthesize a self-assembled mixed-dimensional heterostructure with 2D borophene and 1D armchair-oriented graphene nanoribbons (aGNRs)\",\n",
            "  \"solution\": \"Deposit boron on a substrate to ...'\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSONDecodeError: 'Extra data: line 7 column 1 (char 328)'\n",
            "DEBUG extract_concepts: Stringa JSON (pulita) che ha causato l'errore (primi 200): '{\n",
            "  \"function\": \"Diagnose and determine prognosis of gastric cancer in a subject\",\n",
            "  \"solution\": \"By detecting suppressed expression of the REC8 gene due to elevated methylation level in its genomic s...'\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSONDecodeError: 'Extra data: line 7 column 1 (char 328)'\n",
            "DEBUG extract_concepts: Stringa JSON (pulita) che ha causato l'errore (primi 200): '{\n",
            "  \"function\": \"Diagnose and determine prognosis of gastric cancer in a subject\",\n",
            "  \"solution\": \"By detecting suppressed expression of the REC8 gene due to elevated methylation level in its genomic s...'\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSONDecodeError: 'Extra data: line 7 column 1 (char 379)'\n",
            "DEBUG extract_concepts: Stringa JSON (pulita) che ha causato l'errore (primi 200): '{\n",
            "  \"function\": \"Treat, mitigate, or prevent or delay recurrence or metastasis of Trop-2 expressing cancers in a subject\",\n",
            "  \"solution\": \"By administering an effective amount of an anti-Trop-2 antibod...'\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n",
            "DEBUG extract_concepts: JSON PARSATO E VALIDO (con function, solution, application).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check per vedere se l output esiste:\n",
        "!ls -l /content/drive/MyDrive/results_patent_mistral7b_gpu.jsonl\n",
        "#!cat /content/drive/MyDrive/results_patent_mistral7b_gpu.jsonl # ATTENZIONE: stampa tutto il contenuto, usa con cautela se il file è grande"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHhWyu59wARA",
        "outputId": "64fc2b48-3892-468e-9966-5fac07ba77f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 5542 Jun  2 17:37 /content/drive/MyDrive/results_patent_mistral7b_gpu.jsonl\n",
            "{\"function\": \"Synthesize quantum dots with a perovskite crystal structure and specific size using Group IA and Group IVA metals and halogens or their fluorides\", \"solution\": \"Quantum dots are produced by combining a Group IA metal (Rb, Cs, Fr) and a Group IVA metal (Si, Ge, Sn, Pb) with a halogen (F, Cl, Br, I) or its fluoride, resulting in a perovskite crystal structure. The size of the quantum dots is controlled to be between 1 nanometer and 50 nanometers\", \"application\": \"These quantum dots can be applied in various electronic devices, such as solar cells, light-emitting diodes, and transistors, due to their unique optical and electrical properties\", \"patent_id\": \"EP-3168278-A1\"}\n",
            "{\"function\": \"A quantum dot composite material is created with an all-inorganic perovskite quantum dot and a protective modification on its surface.\", \"solution\": \"The all-inorganic perovskite quantum dot, with a chemical formula of CsPb(Cl a Br 1-a-b I b ), is combined with a protective modification on its surface.\", \"application\": \"The quantum dot composite material can be applied in various fields such as optoelectronics, photovoltaics, and display technologies.\", \"patent_id\": \"EP-3192846-A3\"}\n",
            "{\"function\": \"An organic light-emitting display apparatus is designed to enhance the performance of organic light-emitting devices.\", \"solution\": \"This is accomplished by depositing a thin film of a perovskite compound, represented by Formula 1, on the organic light-emitting device. The perovskite compound is positioned in the light emission direction.\", \"application\": \"The organic light-emitting display apparatus can be applied in various display technologies, such as organic light-emitting diodes (OLEDs) and organic photovoltaic cells, to improve their efficiency and performance.\", \"patent_id\": \"EP-3258495-A1\"}\n",
            "{\"function\": \"Synthesize quantum dots with a perovskite crystal structure and specific size using Group IA and Group IVA metals and halogens or their fluorides\", \"solution\": \"Quantum dots are produced by combining a Group IA metal (Rb, Cs, Fr) and a Group IVA metal (Si, Ge, Sn, Pb) with a halogen (F, Cl, Br, I) or its fluoride, resulting in a perovskite crystal structure. The size of the quantum dots is controlled to be between 1 nanometer and 50 nanometers\", \"application\": \"These quantum dots can be applied in various electronic devices, such as solar cells, light-emitting diodes, and transistors, due to their unique optical and electrical properties\", \"patent_id\": \"EP-3412750-A1\"}\n",
            "{\"function\": \"Produces a crystalline A/M/X material layer on a substrate\", \"solution\": \"By disposing a precursor composition on a substrate, consisting of a metal or metalloid cation M, a solvent with acetonitrile, propionitrile, acetone or a mixture, and an alkylamine\", \"application\": \"Can be applied in various industries such as electronics, optoelectronics, and catalysis for producing high-performance materials\", \"patent_id\": \"EP-3427290-B1\"}\n",
            "{\"function\": \"The present invention creates a light absorption layer for high-efficiency photoelectric conversion and solar cell production in the visible and near-infrared light regions.\", \"solution\": \"This is accomplished by using a perovskite compound and Cl-containing quantum dots in the light absorption layer.\", \"application\": \"The invention applies to the fields of photovoltaics and renewable energy technology.\", \"patent_id\": \"EP-3595018-A4\"}\n",
            "{\"function\": \"Provides an ink composition with a semiconductor nanoparticle containing a perovskite compound and a curable resin composition\", \"solution\": \"The semiconductor nanoparticle in the ink composition is made up of a perovskite compound, and the ink composition also includes a curable resin composition. The ratio of oxygen, nitrogen, and carbon atoms in the curable resin composition and solvent follow a specific formula with a Z value of 0.37 or less.\", \"application\": \"This invention can be applied in the field of ink technology, particularly in the development of advanced inks for use in electronic devices, displays, and other applications requiring semiconductor nanoparticles\", \"patent_id\": \"EP-3660109-A4\"}\n",
            "{\"function\": \"Provide a curable composition with a high maintenance rate of quantum yield after curing\", \"solution\": \"Composition contains a fluorescent particle with a perovskite compound, photopolymerizable compound, and photopolymerization initiator, with specific initiator concentration and absorbance to ensure efficient curing\", \"application\": \"Laminated body and display apparatus components, such as screens and films, that require high quantum yield maintenance after curing\", \"patent_id\": \"EP-3875494-A4\"}\n",
            "{\"function\": \"Provide a curable composition with suppressed decrease in quantum yield of film due to heat\", \"solution\": \"Composition contains fluorescent particle with perovskite compound, photopolymerizable compound, photopolymerization initiator, and antioxidant. Film formed by curing composition.\", \"application\": \"Laminated body and display apparatus utilizing the heat-resistant film\", \"patent_id\": \"EP-3875495-A4\"}\n",
            "{\"function\": \"Synthesize quantum dots with a core-shell structure and specific halogen materials, excluding cadmium\", \"solution\": \"Create quantum dots with a core made of a first semiconductor nanocrystal and a shell composed of a material containing at least two different halogens\", \"application\": \"Applicable in fields such as optoelectronics, photovoltaics, and biomedical imaging, where cadmium-free quantum dots are preferred\", \"patent_id\": \"US-10074770-B2\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pe controllare quanti risultati contiene il mio json di output\n",
        "import json\n",
        "import os # Aggiunto per controllare se il file esiste\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Monta Google Drive\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=True) # force_remount può essere utile\n",
        "    print(\"Google Drive montato con successo!\")\n",
        "except Exception as e:\n",
        "    print(f\"Errore durante il montaggio di Google Drive: {e}\")\n",
        "    raise SystemExit(\"Impossibile montare Google Drive. Verifica i permessi.\")\n",
        "\n",
        "def analizza_file_jsonl(percorso_file_jsonl):\n",
        "    \"\"\"\n",
        "    Analizza un file JSONL per contare le righe totali,\n",
        "    gli oggetti JSON validi, e gli ID brevetto unici.\n",
        "    \"\"\"\n",
        "    conteggio_righe_totali = 0\n",
        "    conteggio_oggetti_json_validi = 0\n",
        "    patent_ids_unici_nel_file = set()\n",
        "    errori_parsing_json = 0\n",
        "    righe_senza_patent_id = 0\n",
        "\n",
        "    print(f\"--- Analisi del file: {percorso_file_jsonl} ---\")\n",
        "\n",
        "    if not os.path.exists(percorso_file_jsonl):\n",
        "        print(f\"ERRORE: Il file specificato non è stato trovato: {percorso_file_jsonl}\")\n",
        "        return 0, 0, 0, 0, 0\n",
        "\n",
        "    try:\n",
        "        with open(percorso_file_jsonl, 'r', encoding='utf-8') as f:\n",
        "            for i, riga in enumerate(f):\n",
        "                conteggio_righe_totali += 1\n",
        "                try:\n",
        "                    obj = json.loads(riga)\n",
        "                    conteggio_oggetti_json_validi += 1\n",
        "                    if \"patent_id\" in obj and obj[\"patent_id\"] is not None:\n",
        "                        patent_ids_unici_nel_file.add(str(obj[\"patent_id\"]))\n",
        "                    else:\n",
        "                        righe_senza_patent_id += 1\n",
        "                        # print(f\"Riga {i+1} non contiene 'patent_id' o è None: {riga.strip()[:100]}...\") # Debug opzionale\n",
        "                except json.JSONDecodeError:\n",
        "                    errori_parsing_json += 1\n",
        "                    # print(f\"Riga {i+1} non è un JSON valido: {riga.strip()[:100]}...\") # Debug opzionale\n",
        "\n",
        "        print(f\"Numero totale di righe nel file: {conteggio_righe_totali}\")\n",
        "        print(f\"Numero di oggetti JSON validi parsati: {conteggio_oggetti_json_validi}\")\n",
        "        print(f\"Numero di ID brevetto ('patent_id') UNICI trovati: {len(patent_ids_unici_nel_file)}\")\n",
        "        if righe_senza_patent_id > 0:\n",
        "            print(f\"ATTENZIONE: {righe_senza_patent_id} oggetti JSON validi non avevano una chiave 'patent_id' o era None.\")\n",
        "        if errori_parsing_json > 0:\n",
        "            print(f\"ATTENZIONE: {errori_parsing_json} righe non sono state parsate correttamente come JSON.\")\n",
        "\n",
        "        return conteggio_righe_totali, conteggio_oggetti_json_validi, len(patent_ids_unici_nel_file)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Si è verificato un errore generale durante la lettura del file: {e}\")\n",
        "        return 0, 0, 0\n",
        "\n",
        "# --- ESECUZIONE DELL'ANALISI ---\n",
        "percorso_del_tuo_output_jsonl = \"/content/drive/MyDrive/results_patent_mistral7b_gpu.jsonl\"\n",
        "#funzione di analisi\n",
        "tot_lines, valid_json_obj, unique_ids = analizza_file_jsonl(percorso_del_tuo_output_jsonl)\n",
        "\n",
        "print(\"\\n--- Riepilogo ---\")\n",
        "if tot_lines > 0:\n",
        "    print(f\"Il tuo file di output contiene {tot_lines} righe.\")\n",
        "    print(f\"Di queste, {valid_json_obj} sono state lette come oggetti JSON validi.\")\n",
        "    print(f\"All'interno di questi oggetti JSON validi, sono stati trovati {unique_ids} 'patent_id' unici.\")\n",
        "    print(\"\\nQuesto numero di 'patent_id' unici è quello che viene usato per calcolare le 'righe nuove da processare'.\")\n",
        "else:\n",
        "    if os.path.exists(percorso_del_tuo_output_jsonl):\n",
        "        print(\"Il file di output sembra essere vuoto o illeggibile.\")\n",
        "    else:\n",
        "        print(\"Il file di output non è stato trovato. Verifica il percorso.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1HxwSAR40Lw",
        "outputId": "db6c5d6e-4636-49ba-b049-d1799542ae39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive montato con successo!\n",
            "--- Analisi del file: /content/drive/MyDrive/results_patent_mistral7b_gpu.jsonl ---\n",
            "Numero totale di righe nel file: 8135\n",
            "Numero di oggetti JSON validi parsati: 8135\n",
            "Numero di ID brevetto ('patent_id') UNICI trovati: 7992\n",
            "\n",
            "--- Riepilogo ---\n",
            "Il tuo file di output contiene 8135 righe.\n",
            "Di queste, 8135 sono state lette come oggetti JSON validi.\n",
            "All'interno di questi oggetti JSON validi, sono stati trovati 7992 'patent_id' unici.\n",
            "\n",
            "Questo numero di 'patent_id' unici è quello che viene usato per calcolare le 'righe nuove da processare'.\n"
          ]
        }
      ]
    }
  ]
}